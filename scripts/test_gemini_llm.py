"""
Gemini LLM æœå‹™æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰ Gemini API æ˜¯å¦æ­£å¸¸å·¥ä½œ

æ›´æ–°æ™‚é–“ï¼š2025-12-26 14:32
ä½œè€…ï¼šAI Assistant
ä¿®æ”¹æ‘˜è¦ï¼šå„ªåŒ–éŒ¯èª¤è™•ç†ï¼Œæ·»åŠ é…é¡éŒ¯èª¤è¨ºæ–·å’Œè§£æ±ºæ–¹æ¡ˆå»ºè­°
æ›´æ–°æ™‚é–“ï¼š2025-12-26 14:25
ä½œè€…ï¼šAI Assistant
ä¿®æ”¹æ‘˜è¦ï¼šå»ºç«‹ Gemini LLM æœå‹™æ¸¬è©¦è…³æœ¬ï¼Œé©—è­‰ API Keyã€æ¨¡å‹åç¨±ã€åŸºæœ¬åŠŸèƒ½
"""
import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config import settings
from app.services.llm_service import GeminiLLM, LLMService


async def test_gemini_api_key():
    """æ¸¬è©¦ 1: é©—è­‰ API Key æ˜¯å¦é…ç½®"""
    print("=" * 60)
    print("æ¸¬è©¦ 1: é©—è­‰ API Key é…ç½®")
    print("=" * 60)
    
    # å„ªå…ˆé †åºï¼š1. .env æª”æ¡ˆï¼ˆSettingsï¼‰2. ç’°å¢ƒè®Šæ•¸
    # é€™æ¨£å¯ä»¥ç¢ºä¿å°ˆæ¡ˆé…ç½®çš„ä¸€è‡´æ€§
    api_key = settings.GOOGLE_API_KEY or os.getenv("GOOGLE_API_KEY")
    
    if not api_key:
        print("âŒ API Key æœªé…ç½®")
        print("   è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­ç½® GOOGLE_API_KEY")
        return False
    
    print(f"âœ… API Key å·²é…ç½®: {api_key[:10]}...{api_key[-4:]}")
    return True


async def test_gemini_model_initialization():
    """æ¸¬è©¦ 2: é©—è­‰æ¨¡å‹åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 2: é©—è­‰æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)
    
    try:
        gemini_llm = GeminiLLM()
        
        if gemini_llm._use_real_api:
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            print(f"   ä½¿ç”¨çœŸå¯¦ API: {gemini_llm._use_real_api}")
            print(f"   æ¨¡å‹åç¨±: {settings.GEMINI_MODEL_NAME}")
            if gemini_llm._model:
                print(f"   æ¨¡å‹ç‰©ä»¶: {type(gemini_llm._model).__name__}")
            return True
        else:
            print("âš ï¸ ä½¿ç”¨ Stub æ¨¡å¼ï¼ˆé™ç´šï¼‰")
            if not gemini_llm.api_key:
                print("   åŸå› : API Key æœªé…ç½®")
            else:
                print("   åŸå› : åˆå§‹åŒ–å¤±æ•—æˆ–ä¾è³´å¥—ä»¶æœªå®‰è£")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        return False


async def test_gemini_basic_generation():
    """æ¸¬è©¦ 3: æ¸¬è©¦åŸºæœ¬ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 3: æ¸¬è©¦åŸºæœ¬ç”ŸæˆåŠŸèƒ½")
    print("=" * 60)
    
    try:
        gemini_llm = GeminiLLM()
        
        test_prompt = "è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹äººå·¥æ™ºæ…§ã€‚"
        print(f"æ¸¬è©¦æç¤ºè©: {test_prompt}")
        print("æ­£åœ¨å‘¼å« Gemini API...")
        
        result = await gemini_llm.generate(test_prompt, max_tokens=100, temperature=0.7)
        
        if result and not result.startswith("[Gemini Stub]"):
            print(f"âœ… API å‘¼å«æˆåŠŸ")
            print(f"   å›æ‡‰é•·åº¦: {len(result)} å­—å…ƒ")
            print(f"   å›æ‡‰é è¦½: {result[:100]}...")
            return True
        else:
            print("âš ï¸ ä½¿ç”¨ Stub æ¨¡å¼ï¼ˆé™ç´šï¼‰")
            print(f"   å›æ‡‰: {result[:100]}...")
            return False
            
    except Exception as e:
        error_str = str(e)
        print(f"âŒ API å‘¼å«å¤±æ•—: {error_str}")
        
        if "429" in error_str or "quota" in error_str.lower():
            print("   åŸå› : API é…é¡å·²ç”¨å®Œï¼ˆå…è²»å±¤é…é¡é™åˆ¶ï¼‰")
            print("   è©³ç´°è³‡è¨Š:")
            if "free_tier" in error_str:
                print("     - å…è²»å±¤é…é¡å·²ç”¨å®Œ")
                print("     - éœ€è¦ç­‰å¾…é…é¡é‡ç½®æˆ–å‡ç´šåˆ°ä»˜è²»æ–¹æ¡ˆ")
            if "retry_delay" in error_str or "retry in" in error_str:
                import re
                retry_match = re.search(r'retry in ([\d.]+)s', error_str)
                if retry_match:
                    retry_seconds = float(retry_match.group(1))
                    retry_minutes = retry_seconds / 60
                    print(f"     - å»ºè­°ç­‰å¾… {retry_minutes:.1f} åˆ†é˜å¾Œé‡è©¦")
            print("   è§£æ±ºæ–¹æ¡ˆ:")
            print("     1. ç­‰å¾…é…é¡é‡ç½®ï¼ˆé€šå¸¸æ¯åˆ†é˜æˆ–æ¯å¤©é‡ç½®ï¼‰")
            print("     2. å‡ç´šåˆ° Google Cloud ä»˜è²»æ–¹æ¡ˆ")
            print("     3. æª¢æŸ¥é…é¡ä½¿ç”¨æƒ…æ³: https://ai.dev/usage?tab=rate-limit")
            print("     4. æš«æ™‚ä½¿ç”¨ Stub æ¨¡å¼ï¼ˆå·²è‡ªå‹•é™ç´šï¼‰")
        elif "404" in error_str:
            print("   åŸå› : æ¨¡å‹åç¨±ä¸æ­£ç¢ºæˆ–æ¨¡å‹ä¸å­˜åœ¨")
            print(f"   ç•¶å‰æ¨¡å‹: {settings.GEMINI_MODEL_NAME}")
            print("   å»ºè­°å˜—è©¦ä»¥ä¸‹æ¨¡å‹:")
            print("     - gemini-1.5-flashï¼ˆç©©å®šï¼Œæ¨è–¦ï¼‰")
            print("     - gemini-1.5-proï¼ˆæ›´å¼·ï¼‰")
            print("     - gemini-1.0-proï¼ˆèˆŠç‰ˆï¼‰")
        elif "401" in error_str or "403" in error_str:
            print("   åŸå› : API Key ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³")
            print("   å»ºè­°:")
            print("     1. æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢º")
            print("     2. ç¢ºèª API Key æ˜¯å¦æœ‰ Gemini API æ¬Šé™")
            print("     3. é‡æ–°ç”Ÿæˆ API Key: https://makersuite.google.com/app/apikey")
        else:
            print(f"   éŒ¯èª¤é¡å‹: {type(e).__name__}")
            print("   å»ºè­°: æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ä¸¦æŸ¥çœ‹ Gemini API æ–‡æª”")
        
        return False


async def test_gemini_streaming():
    """æ¸¬è©¦ 4: æ¸¬è©¦ä¸²æµç”ŸæˆåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 4: æ¸¬è©¦ä¸²æµç”ŸæˆåŠŸèƒ½")
    print("=" * 60)
    
    try:
        gemini_llm = GeminiLLM()
        
        test_prompt = "è«‹æ•¸æ•¸ 1 åˆ° 5ã€‚"
        print(f"æ¸¬è©¦æç¤ºè©: {test_prompt}")
        print("æ­£åœ¨å‘¼å« Gemini APIï¼ˆä¸²æµæ¨¡å¼ï¼‰...")
        
        chunks = []
        async for chunk in gemini_llm.generate_chunk(test_prompt):
            chunks.append(chunk)
            print(f"   æ”¶åˆ°ç‰‡æ®µ: {chunk[:50]}...")
            if len(chunks) >= 3:  # åªé¡¯ç¤ºå‰ 3 å€‹ç‰‡æ®µ
                break
        
        if chunks and not chunks[0].startswith("[Gemini Stub]"):
            print(f"âœ… ä¸²æµ API å‘¼å«æˆåŠŸ")
            print(f"   æ”¶åˆ° {len(chunks)} å€‹ç‰‡æ®µ")
            return True
        else:
            print("âš ï¸ ä½¿ç”¨ Stub æ¨¡å¼ï¼ˆé™ç´šï¼‰")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸²æµ API å‘¼å«å¤±æ•—: {str(e)}")
        return False


async def test_llm_service_integration():
    """æ¸¬è©¦ 5: æ¸¬è©¦ LLMService æ•´åˆ"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 5: æ¸¬è©¦ LLMService æ•´åˆ")
    print("=" * 60)
    
    try:
        llm_service = LLMService(provider="gemini")
        
        test_prompt = "ä»€éº¼æ˜¯ GraphRAGï¼Ÿ"
        print(f"æ¸¬è©¦æç¤ºè©: {test_prompt}")
        print("æ­£åœ¨å‘¼å« LLMService...")
        
        result = await llm_service.generate(test_prompt, max_tokens=200)
        
        if result and not result.startswith("[Gemini Stub]"):
            print(f"âœ… LLMService æ•´åˆæˆåŠŸ")
            print(f"   å›æ‡‰é•·åº¦: {len(result)} å­—å…ƒ")
            print(f"   å›æ‡‰é è¦½: {result[:150]}...")
            return True
        else:
            print("âš ï¸ ä½¿ç”¨ Stub æ¨¡å¼ï¼ˆé™ç´šï¼‰")
            return False
            
    except Exception as e:
        print(f"âŒ LLMService æ•´åˆå¤±æ•—: {str(e)}")
        return False


async def test_available_models():
    """æ¸¬è©¦ 6: åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 6: æª¢æŸ¥å¯ç”¨æ¨¡å‹")
    print("=" * 60)
    
    try:
        import google.generativeai as genai
        
        # å„ªå…ˆé †åºï¼š1. .env æª”æ¡ˆï¼ˆSettingsï¼‰2. ç’°å¢ƒè®Šæ•¸
        # é€™æ¨£å¯ä»¥ç¢ºä¿å°ˆæ¡ˆé…ç½®çš„ä¸€è‡´æ€§
        api_key = settings.GOOGLE_API_KEY or os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âš ï¸ API Key æœªé…ç½®ï¼Œç„¡æ³•æª¢æŸ¥å¯ç”¨æ¨¡å‹")
            return False
        
        genai.configure(api_key=api_key)
        
        print("æ­£åœ¨æŸ¥è©¢å¯ç”¨æ¨¡å‹...")
        models = genai.list_models()
        
        available_models = []
        for model in models:
            if 'generateContent' in model.supported_generation_methods:
                available_models.append(model.name)
        
        if available_models:
            print(f"âœ… æ‰¾åˆ° {len(available_models)} å€‹å¯ç”¨æ¨¡å‹:")
            for model in available_models[:10]:  # åªé¡¯ç¤ºå‰ 10 å€‹
                print(f"   - {model}")
            
            # æª¢æŸ¥ç•¶å‰é…ç½®çš„æ¨¡å‹æ˜¯å¦å¯ç”¨
            current_model = settings.GEMINI_MODEL_NAME
            if any(current_model in model for model in available_models):
                print(f"\nâœ… ç•¶å‰é…ç½®çš„æ¨¡å‹ '{current_model}' å¯ç”¨")
            else:
                print(f"\nâš ï¸ ç•¶å‰é…ç½®çš„æ¨¡å‹ '{current_model}' ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")
                print("   å»ºè­°ä½¿ç”¨ä»¥ä¸‹æ¨¡å‹ä¹‹ä¸€:")
                for model in available_models[:5]:
                    print(f"   - {model}")
            
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")
            return False
            
    except ImportError:
        print("âš ï¸ google-generativeai æœªå®‰è£")
        print("   è«‹åŸ·è¡Œ: pip install google-generativeai")
        return False
    except Exception as e:
        print(f"âŒ æŸ¥è©¢æ¨¡å‹å¤±æ•—: {str(e)}")
        return False


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("\n" + "=" * 60)
    print("Gemini LLM æœå‹™æ¸¬è©¦")
    print("=" * 60)
    print(f"ç•¶å‰é…ç½®:")
    print(f"  LLM_PROVIDER: {settings.LLM_PROVIDER}")
    print(f"  GEMINI_MODEL_NAME: {settings.GEMINI_MODEL_NAME}")
    print(f"  GOOGLE_API_KEY (ENV): {'å·²é…ç½®' if os.getenv('GOOGLE_API_KEY') else 'æœªé…ç½®'}")
    print(f"  GOOGLE_API_KEY (Settings): {'å·²é…ç½®' if settings.GOOGLE_API_KEY else 'æœªé…ç½®'}")
    
    results = []
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    results.append(("API Key é…ç½®", await test_gemini_api_key()))
    
    if results[-1][1]:  # å¦‚æœ API Key å·²é…ç½®ï¼Œç¹¼çºŒæ¸¬è©¦
        results.append(("æ¨¡å‹åˆå§‹åŒ–", await test_gemini_model_initialization()))
        results.append(("åŸºæœ¬ç”Ÿæˆ", await test_gemini_basic_generation()))
        results.append(("ä¸²æµç”Ÿæˆ", await test_gemini_streaming()))
        results.append(("LLMService æ•´åˆ", await test_llm_service_integration()))
        results.append(("å¯ç”¨æ¨¡å‹", await test_available_models()))
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœæ‘˜è¦
    print("\n" + "=" * 60)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{status}: {test_name}")
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Gemini LLM æœå‹™æ­£å¸¸å·¥ä½œã€‚")
    elif passed > 0:
        print("\nâš ï¸ éƒ¨åˆ†æ¸¬è©¦é€šéï¼Œè«‹æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦é …ç›®ã€‚")
    else:
        print("\nâŒ æ‰€æœ‰æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®å’Œ API Keyã€‚")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·ï¼ˆCtrl+Cï¼‰")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

